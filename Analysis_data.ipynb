{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q1 ... finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check if you have not missing value\n",
    "home_team = pd.read_csv(\"tennis_data/home_team.csv\")\n",
    "away_team = pd.read_csv(\"tennis_data/away_team.csv\")\n",
    "home_team = home_team[['full_name','player_id']]\n",
    "away_team = away_team[['full_name','player_id']]\n",
    "all_teams = pd.concat([home_team , away_team] ,join = 'outer')\n",
    "all_teams.drop_duplicates(subset=['player_id'] , inplace = True)\n",
    "all_teams.sort_values('full_name' , inplace = True)\n",
    "all_teams.reset_index(drop=True , inplace = True)\n",
    "num_players = all_teams['player_id'].nunique()\n",
    "print(f'the number of players is: {num_players}')\n",
    "all_teams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q3 ... finished "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "full_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "num_won",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_game",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "win_percentage",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "5b7b0e0a-78e6-448d-97d1-41c40bc34730",
       "rows": [
        [
         "Oluwadare, Hephzibah",
         "1",
         "1",
         "100.0"
        ],
        [
         "Bu, Yunchaokete",
         "1",
         "1",
         "100.0"
        ],
        [
         "Wu, Yibing",
         "2",
         "2",
         "100.0"
        ],
        [
         "Marti, Yann",
         "2",
         "2",
         "100.0"
        ],
        [
         "Sinner, Jannik",
         "15",
         "16",
         "93.75"
        ],
        [
         "Valentova, Tereza",
         "14",
         "15",
         "93.33333333333333"
        ],
        [
         "Swiatek, Iga",
         "16",
         "18",
         "88.88888888888889"
        ],
        [
         "Ciric Bagaric, Lucija",
         "15",
         "17",
         "88.23529411764706"
        ],
        [
         "Plipuech, Peangtarn",
         "7",
         "8",
         "87.5"
        ],
        [
         "Henning, Philip",
         "13",
         "15",
         "86.66666666666667"
        ],
        [
         "Chidekh, Clement",
         "23",
         "27",
         "85.18518518518519"
        ],
        [
         "Tu, Li",
         "11",
         "13",
         "84.61538461538461"
        ],
        [
         "Kwiatkowski, Thai-Son",
         "11",
         "13",
         "84.61538461538461"
        ],
        [
         "Bouzas Maneiro, Jessica",
         "16",
         "19",
         "84.21052631578947"
        ],
        [
         "Faria, Jaime",
         "20",
         "24",
         "83.33333333333334"
        ],
        [
         "Majchrzak, Kamil",
         "15",
         "18",
         "83.33333333333334"
        ],
        [
         "Nicod, Jakub",
         "14",
         "17",
         "82.35294117647058"
        ],
        [
         "Gao, Xinyu",
         "9",
         "11",
         "81.81818181818183"
        ],
        [
         "Gimeno Valero, Carlos",
         "9",
         "11",
         "81.81818181818183"
        ],
        [
         "Toth, Amarissa Kiara",
         "13",
         "16",
         "81.25"
        ],
        [
         "Begu, Irina-Camelia",
         "4",
         "5",
         "80.0"
        ],
        [
         "Legout, Timo",
         "4",
         "5",
         "80.0"
        ],
        [
         "Medvedev, Daniil",
         "12",
         "15",
         "80.0"
        ],
        [
         "Massara, Antonio",
         "4",
         "5",
         "80.0"
        ],
        [
         "Dellien Velasco, Murkel Alejandro",
         "20",
         "25",
         "80.0"
        ],
        [
         "Siskova, Anna",
         "8",
         "10",
         "80.0"
        ],
        [
         "Rybakina, Elena",
         "15",
         "19",
         "78.94736842105263"
        ],
        [
         "Baez, Sebastian",
         "15",
         "19",
         "78.94736842105263"
        ],
        [
         "Pridankina, Elena",
         "15",
         "19",
         "78.94736842105263"
        ],
        [
         "Virtanen, Otto",
         "15",
         "19",
         "78.94736842105263"
        ],
        [
         "Yuan, Yue",
         "11",
         "14",
         "78.57142857142857"
        ],
        [
         "Alcaraz, Carlos",
         "11",
         "14",
         "78.57142857142857"
        ],
        [
         "Laskevich, Evialina",
         "11",
         "14",
         "78.57142857142857"
        ],
        [
         "Kung, Leonie",
         "11",
         "14",
         "78.57142857142857"
        ],
        [
         "Collins, Danielle",
         "18",
         "23",
         "78.26086956521739"
        ],
        [
         "Popko, Dmitry",
         "28",
         "36",
         "77.77777777777779"
        ],
        [
         "Budkov Kjaer, Nicolai",
         "7",
         "9",
         "77.77777777777779"
        ],
        [
         "Kozakova, Karolina",
         "7",
         "9",
         "77.77777777777779"
        ],
        [
         "Manasse, Maegan",
         "10",
         "13",
         "76.92307692307693"
        ],
        [
         "Munk Mortensen, Rebecca",
         "10",
         "13",
         "76.92307692307693"
        ],
        [
         "Fita Boluda, Ángela",
         "10",
         "13",
         "76.92307692307693"
        ],
        [
         "Shibahara, Ena",
         "10",
         "13",
         "76.92307692307693"
        ],
        [
         "Shubladze, Alexandra",
         "10",
         "13",
         "76.92307692307693"
        ],
        [
         "Šrámková, Rebecca",
         "10",
         "13",
         "76.92307692307693"
        ],
        [
         "Dimitrov, Grigor",
         "13",
         "17",
         "76.47058823529412"
        ],
        [
         "de Minaur, Alex",
         "13",
         "17",
         "76.47058823529412"
        ],
        [
         "Dodig, Matej",
         "13",
         "17",
         "76.47058823529412"
        ],
        [
         "Gengel, Marek",
         "19",
         "25",
         "76.0"
        ],
        [
         "Svajda, Trevor",
         "6",
         "8",
         "75.0"
        ],
        [
         "Möller, Marvin",
         "3",
         "4",
         "75.0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 2073
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_won</th>\n",
       "      <th>num_game</th>\n",
       "      <th>win_percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Oluwadare, Hephzibah</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bu, Yunchaokete</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wu, Yibing</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marti, Yann</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sinner, Jannik</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>93.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alkotop, Mousa</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>De Dios, Felipe</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ilkel, Berk</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>6.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vetrih, Miha</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>6.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agostini, Simone</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5.882353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2073 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      num_won  num_game  win_percentage\n",
       "full_name                                              \n",
       "Oluwadare, Hephzibah        1         1      100.000000\n",
       "Bu, Yunchaokete             1         1      100.000000\n",
       "Wu, Yibing                  2         2      100.000000\n",
       "Marti, Yann                 2         2      100.000000\n",
       "Sinner, Jannik             15        16       93.750000\n",
       "...                       ...       ...             ...\n",
       "Alkotop, Mousa              1        15        6.666667\n",
       "De Dios, Felipe             1        15        6.666667\n",
       "Ilkel, Berk                 1        16        6.250000\n",
       "Vetrih, Miha                1        16        6.250000\n",
       "Agostini, Simone            1        17        5.882353\n",
       "\n",
       "[2073 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_team = pd.read_csv(\"tennis_data/home_team.csv\")\n",
    "away_team = pd.read_csv(\"tennis_data/away_team.csv\")\n",
    "event = pd.read_csv(\"tennis_data/event.csv\")\n",
    "\n",
    "home_team = home_team[['match_id','player_id' ,'full_name']]\n",
    "away_team = away_team[['match_id','player_id' ,'full_name']]\n",
    "\n",
    "all_home = home_team.drop_duplicates(subset = ['match_id'])\n",
    "all_away = away_team.drop_duplicates(subset = ['match_id'])\n",
    "all_play = pd.concat([all_home , all_away])\n",
    "all_play = all_play.groupby('full_name').agg(\n",
    "    num_game = ('player_id' , 'count')\n",
    ")\n",
    "\n",
    "players = pd.merge(home_team , away_team , how = \"inner\" , on = \"match_id\" , suffixes=[\"_home\" , \"_away\"])\n",
    "players.drop_duplicates(subset = ['match_id'] , inplace = True)\n",
    "\n",
    "\n",
    "event = event[event['winner_code'].notnull()].drop_duplicates(subset=['match_id']).sort_values('match_id')\n",
    "event = event[['match_id' , 'winner_code']]\n",
    "event.reset_index(drop=True , inplace = True)\n",
    "    \n",
    "final = pd.merge(players , event , on = 'match_id' , how = 'inner')\n",
    "final_home = final[final['winner_code'] == 1.0].copy()\n",
    "final_away = final[final['winner_code'] == 2.0].copy()\n",
    "final_home = final_home[['full_name_home' , 'player_id_home']].sort_values('full_name_home').rename(columns={'player_id_home':'player_id' , 'full_name_home' :'full_name'})\n",
    "final_away = final_away[['full_name_away' , 'player_id_away']].sort_values('full_name_away').rename(columns={'player_id_away':'player_id' , 'full_name_away' :'full_name'})\n",
    "\n",
    "final = pd.concat([final_home , final_away])\n",
    "final.sort_values('full_name' , inplace = True)\n",
    "final = final.groupby('full_name').agg(\n",
    "    num_won = ('player_id' , 'count')\n",
    ")\n",
    "\n",
    "final = pd.merge(final , all_play , on = 'full_name' , how = 'left')\n",
    "final['win_percentage'] = final['num_won'].div(final['num_game']) * 100\n",
    "final.sort_values('win_percentage' , ascending=False)\n",
    "# ax = sns.barplot(num_win[:4], x=\"full_name\", y=\"count\")\n",
    "# you can use number of games and win_games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q5 ... finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data and clear\n",
    "time = pd.read_csv(\"tennis_data/time.csv\")\n",
    "time.drop_duplicates(subset = ['match_id'] , inplace=True)\n",
    "time.dropna(subset = ['period_1'] , inplace = True)\n",
    "time.dropna(subset = ['period_2'] , inplace = True)\n",
    "\n",
    "# check if you have period_4 or period_5\n",
    "print(time['period_4'].notnull().any())\n",
    "print(time['period_5'].notnull().any())\n",
    "\n",
    "# drop period_4 and period_5 and fill null with 0\n",
    "time.drop(['period_4' , 'period_5' ,'current_period_start_timestamp']  , axis = 'columns', inplace = True )\n",
    "values = {'period_3':0}\n",
    "time.fillna(value = values , inplace = True)\n",
    "time.loc[time['period_3'] == 0 , 'num_set'] = 2\n",
    "time.loc[time['period_3'] != 0 , 'num_set'] = 3\n",
    "finall = time.groupby('num_set').agg(\n",
    "    number_of_sets = ('num_set' , 'count')\n",
    ")\n",
    "total = finall['number_of_sets'].sum()\n",
    "finall['number_of_set_percentage'] = (finall['number_of_sets'].div(total)) * 100\n",
    "finall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q7 ... finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "aces = pd.read_csv(\"tennis_data/period.csv\")\n",
    "aces = aces[aces['period'] == 'ALL'][aces['statistic_name'] == 'aces'].drop(['period' , 'statistic_category_name' , 'compare_code' ,'statistic_type' , 'value_type' , 'home_value' , 'away_value' , 'home_total' , 'away_total'] , axis='columns')\n",
    "aces = aces.drop_duplicates(subset=['match_id']).sort_values('match_id')\n",
    "aces = aces.astype({'home_stat':'int32' , 'away_stat':'int32'})\n",
    "\n",
    "# check home&away stat is not null\n",
    "aces.dropna(subset = ['home_stat' , 'away_stat'] , inplace=True)\n",
    "aces['number_of_aces'] = aces['home_stat'].add(aces['away_stat'])\n",
    "aces = aces.drop(['statistic_name' , 'home_stat' ,  'away_stat'] , axis = 'columns').sort_values('number_of_aces' , ascending=False)\n",
    "aces.reset_index(drop=True , inplace = True)\n",
    "mean = aces['number_of_aces'].describe()\n",
    "mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q9 ... finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# import data\n",
    "time = pd.read_csv(\"tennis_data/time.csv\")\n",
    "home_team = pd.read_csv(\"tennis_data/home_team.csv\")\n",
    "away_team = pd.read_csv(\"tennis_data/away_team.csv\")\n",
    "event = pd.read_csv(\"tennis_data/event.csv\")\n",
    "tournament = pd.read_csv(\"tennis_data/tournament.csv\")\n",
    "\n",
    "# clear data & choose desired data & seprate time of matches\n",
    "date = time.drop_duplicates(subset = 'match_id').dropna(subset = 'current_period_start_timestamp').copy()\n",
    "date = date[['match_id' , 'current_period_start_timestamp']]\n",
    "date = date.astype({'current_period_start_timestamp':'int32'})\n",
    "date['play_in_month'] = 0\n",
    "for dt in date['match_id']:\n",
    "    date.loc[date['match_id'] == dt , 'play_in_month']  = datetime.fromtimestamp(int(date[date['match_id'] == dt]['current_period_start_timestamp'])).month\n",
    "\n",
    "\n",
    "month_1 = date[date['play_in_month'] == 1]\n",
    "month_2 = date[date['play_in_month'] == 2]\n",
    "month_3 = date[date['play_in_month'] == 3]\n",
    "month_4 = date[date['play_in_month'] == 4]\n",
    "\n",
    "\n",
    "home_team = home_team[['full_name' , 'player_id' , 'match_id']]\n",
    "away_team = away_team[['full_name' , 'player_id' , 'match_id']]\n",
    "players = pd.merge(home_team , away_team , how = \"inner\" , on = \"match_id\" , suffixes=[\"_home\" , \"_away\"])\n",
    "players.drop_duplicates(subset = ['match_id'] , inplace = True)\n",
    "\n",
    "\n",
    "event = event[event['winner_code'].notnull()].drop_duplicates(subset=['match_id']).sort_values('match_id')\n",
    "event = event[['match_id' , 'winner_code']]\n",
    "event.reset_index(drop = True , inplace = True)\n",
    "\n",
    "winner = pd.merge(players , event , on = 'match_id' , how = 'inner')\n",
    "\n",
    "winner.loc[winner['winner_code'] == 1 , 'winner_name'] = winner['full_name_home']\n",
    "winner.loc[winner['winner_code'] == 1 , 'winner_id'] = winner['player_id_home']\n",
    "winner.loc[winner['winner_code'] == 2 , 'winner_name'] = winner['full_name_away']\n",
    "winner.loc[winner['winner_code'] == 2 , 'winner_id'] = winner['player_id_away']\n",
    "winner = winner[['match_id' , 'winner_name' , 'winner_id']]\n",
    "\n",
    "\n",
    "tournament = tournament[['match_id' , 'tournament_id']]\n",
    "tournament.drop_duplicates(subset = 'match_id' , inplace = True)\n",
    "\n",
    "play_tour = pd.merge(winner , tournament , on = 'match_id' , how = 'inner')\n",
    "month_1 = pd.merge(month_1 , play_tour , on = 'match_id' , how = 'inner')\n",
    "month_2 = pd.merge(month_2 , play_tour , on = 'match_id' , how = 'inner')\n",
    "month_3 = pd.merge(month_3 , play_tour , on = 'match_id' , how = 'inner')\n",
    "month_4 = pd.merge(month_4 , play_tour , on = 'match_id' , how = 'inner')\n",
    "month_1 = month_1[['winner_name' , 'winner_id' , 'tournament_id']]\n",
    "month_2 = month_2[['winner_name' , 'winner_id' , 'tournament_id']]\n",
    "month_3 = month_3[['winner_name' , 'winner_id' , 'tournament_id']]\n",
    "month_4 = month_4[['winner_name' , 'winner_id' , 'tournament_id']]\n",
    "\n",
    "\n",
    "monthes = [month_1 , month_2 , month_3 , month_4]\n",
    "finall = pd.DataFrame({'tournament_id':1234 , 'month':[1,2,3,4] , 'winner_name':'A' , 'number_of_win':0}) # generate finall dataframe with default values\n",
    "for indx , mnth in enumerate(monthes):\n",
    "    counts = mnth.groupby(['tournament_id' , 'winner_name']).size().reset_index(name = 'count')\n",
    "    max_counts = counts.groupby('tournament_id')['count'].transform('max')\n",
    "    result = counts[counts['count'] == max_counts].sort_values(['count' , 'tournament_id'] , ascending=False)\n",
    "    result = result.astype({'winner_name':'str'})\n",
    "    finall.loc[finall['month'] == indx + 1 , 'winner_name'] = result.iloc[0]['winner_name']\n",
    "    finall.loc[finall['month'] == indx + 1 , 'number_of_win'] = result.iloc[0]['count']\n",
    "    finall.loc[finall['month'] == indx + 1 , 'tournament_id'] = result.iloc[0]['tournament_id']\n",
    "\n",
    "finall\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q11 ... finished "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data and clear\n",
    "time = pd.read_csv(\"tennis_data/time.csv\")\n",
    "time.sort_values('match_id' , inplace = True)\n",
    "time.drop_duplicates(subset = ['match_id'] , inplace=True)\n",
    "time.dropna(subset = ['period_1'] , inplace = True)\n",
    "time.dropna(subset = ['period_2'] , inplace = True)\n",
    "\n",
    "# check if you have period_4 or period_5\n",
    "print(time['period_4'].notnull().any())\n",
    "print(time['period_5'].notnull().any())\n",
    "\n",
    "# drop period_4 and period_5 and fill null with 0\n",
    "time.drop(['period_4' , 'period_5' ,'current_period_start_timestamp']  , axis = 'columns', inplace = True )\n",
    "values = {'period_3':'0'}\n",
    "time.fillna(value = values , inplace = True)\n",
    "# casting type to int32\n",
    "time = time.astype({'period_1':'int32' , 'period_2':'int32' , 'period_3':'int32'})\n",
    "\n",
    "# calculate match_time\n",
    "time['period1 + period2'] = time['period_1'].add(time['period_2'])\n",
    "time['total_period'] = time['period1 + period2'].add(time['period_3'])\n",
    "mean_duration = time['total_period'].mean()\n",
    "mean_duration\n",
    "\n",
    "# calculate time\n",
    "def convert(x):\n",
    "    hour = x // 3600\n",
    "    minute = (x - (3600*hour)) // 60\n",
    "    seconds = x - ((3600*hour) + (minute*60))\n",
    "   \n",
    "    return \"%d:%02d:%02d\" % (hour, minute, seconds)\n",
    "\n",
    "print(convert(mean_duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q13 ... finished "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data \n",
    "home_team = pd.read_csv(\"tennis_data/home_team.csv\")\n",
    "away_team = pd.read_csv(\"tennis_data/away_team.csv\")\n",
    "\n",
    "# choose desired columns & drop duplicate data & groupby based on country\n",
    "home_team = home_team[['full_name' , 'player_id' , 'plays']]\n",
    "away_team = away_team[['full_name' , 'player_id' , 'plays']]\n",
    "home_team.dropna(subset=['plays'] , inplace = True)\n",
    "away_team.dropna(subset= ['plays'] , inplace = True)\n",
    "data = pd.concat([home_team , away_team])\n",
    "data.drop_duplicates(subset = ['player_id'] , inplace = True)\n",
    "\n",
    "# generate desired info\n",
    "finall = data.groupby('plays').agg(\n",
    "    number_of_players = ('plays' , 'count')\n",
    ")\n",
    "total = finall['number_of_players'].sum()\n",
    "finall['number_of_players_percentage'] = (finall['number_of_players'].div(total)) * 100\n",
    "finall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q15 ... finished "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data \n",
    "home_team = pd.read_csv(\"tennis_data/home_team.csv\")\n",
    "away_team = pd.read_csv(\"tennis_data/away_team.csv\")\n",
    "venue = pd.read_csv(\"tennis_data/venue.csv\")\n",
    "\n",
    "## choose desired columns & drop duplicate data & groupby based on country\n",
    "# 1. home_team & away_team \n",
    "home_team = home_team[['country' , 'player_id']]\n",
    "away_team = away_team[['country' , 'player_id']]\n",
    "\n",
    "home_team.dropna(subset=['country'] , inplace = True)\n",
    "away_team.dropna(subset= ['country'] , inplace = True)\n",
    "\n",
    "# 2. total_player\n",
    "total_player = pd.concat([home_team , away_team])\n",
    "total_player.drop_duplicates(subset = ['player_id'] , inplace = True)\n",
    "total_player = total_player.groupby('country').agg(\n",
    "    total_player = ('player_id' , 'count')\n",
    ")\n",
    "\n",
    "home_team.drop_duplicates(subset = ['player_id'] , inplace = True)\n",
    "away_team.drop_duplicates(subset = ['player_id'] , inplace = True)\n",
    "\n",
    "home_team = home_team.groupby('country').agg(\n",
    "    number_of_home_players = ('player_id' , 'count')\n",
    ")\n",
    "away_team = away_team.groupby('country').agg(\n",
    "    number_of_away_players = ('player_id' , 'count')\n",
    ")\n",
    "\n",
    "# 3. venue  \n",
    "venue.drop_duplicates(subset = 'match_id' , inplace = True)\n",
    "venue = venue[['country' , 'match_id']].sort_values('country')\n",
    "venue = venue.groupby('country').agg(\n",
    "    number_of_game_played = ('match_id','count')\n",
    ")\n",
    "\n",
    "# merging data\n",
    "total = pd.merge(home_team , away_team , on = 'country' , how = 'outer').fillna(0)\n",
    "total = pd.merge(total , total_player , on = 'country' , how = 'outer')\n",
    "total = pd.merge(total , venue  , on = 'country' , how = 'outer').fillna(0)\n",
    "\n",
    "# generate desired info\n",
    "all_countries = total.shape[0]\n",
    "\n",
    "have_player = (total[total['total_player'] !=  0].shape[0]) / all_countries * 100\n",
    "\n",
    "match_organizer = (total[total['number_of_game_played'] !=  0].shape[0]) / all_countries * 100\n",
    "\n",
    "have_player_match_organizer = (total[total['number_of_game_played'] !=  0][total['total_player'] !=  0].shape[0]) / all_countries * 100\n",
    "\n",
    "just_organizer = (total[total['number_of_game_played'] !=  0][total['total_player'] ==  0].shape[0]) / all_countries * 100\n",
    "\n",
    "just_player = (total[total['number_of_game_played'] ==  0][total['total_player'] !=  0].shape[0]) / all_countries * 100\n",
    "\n",
    "# data = [have_player_match_organizer, just_organizer, just_player]\n",
    "# # Creating plot\n",
    "# fig = plt.figure(figsize=(7, 7))\n",
    "# plt.pie(data , labels = ['have_player_match_organizer' , 'just_organizer' , 'just_player'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q17 ... finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = pd.read_csv(\"tennis_data/period.csv\")\n",
    "time = time[time['period'] == 'ALL'][time['statistic_name'].isin(['service_games_played' , 'service_games_won'])].drop_duplicates(['match_id' , 'statistic_name']).sort_values(['match_id'])\n",
    "time = time[['match_id' , 'statistic_name' , 'home_stat' , 'away_stat']]\n",
    "time = time.astype({'home_stat':'int32' , 'away_stat':'int32'})\n",
    "time['total'] = time['home_stat'].add(time['away_stat'])\n",
    "final = time.pivot_table(values = 'total' , columns='statistic_name' , index = 'match_id')\n",
    "out = final[final['service_games_played']<final['service_games_won']].index\n",
    "final.drop(out , inplace = True)\n",
    "final['breake_serve'] = final['service_games_played'].subtract(final['service_games_won'])\n",
    "final.sort_values('breake_serve' , ascending = False)\n",
    "# sns.boxplot(data=final['breake_serve'])\n",
    "# sns.violinplot(x=final['breake_serve'])\n",
    "# sns.displot(final, x=\"breake_serve\", binwidth=3)\n",
    "g = sns.catplot(\n",
    "    data=final,\n",
    "    x=\"breake_serve\",\n",
    "    kind=\"box\", orient=\"h\",\n",
    "     margin_titles=True,\n",
    "    height=2.0, aspect=5,\n",
    ")\n",
    "g.set(xlabel=\"Breake_serve\", ylabel=\"count\")\n",
    "final['breake_serve'].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
